{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sarah Bernardo\n",
    "\n",
    "CS 4120, Spring 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/sarahbernardo/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sarahbernardo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sarahbernardo/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sarahbernardo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import model from the nb_model.py file and all other relevant packages\n",
    "import nb_model as nb\n",
    "import time\n",
    "import movies_data_utils as mdu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "NUM_TRAINING_EXAMPLES = 625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Wikipedia plot movie data from https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots\n",
    "plots, genres = mdu.get_plots_genres('movie_plots.json')\n",
    "\n",
    "# split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(plots[:NUM_TRAINING_EXAMPLES], \n",
    "                                                    genres[:NUM_TRAINING_EXAMPLES], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: ['amateur ghost hunter visit abandoned house investigation turn massacre leaving question detective psychologist', 'youtuber becomes obsessed figuring copycat archnemesis manages steal idea', 'girlfriend learns truth murky past con artist forced examine choice get root real identity']\n",
      "y_train: ['Horror', 'Comedies', 'Comedies']\n",
      "X_train shape: (500, 1)\n",
      "y_train shape: (500, 1)\n",
      "X_test shape: (125, 1)\n",
      "y_test shape: (125, 1)\n"
     ]
    }
   ],
   "source": [
    "# see what the data looks like by printing the first 3 rows of the training set\n",
    "# and their corresponding labels\n",
    "\n",
    "print('X_train:', X_train[:3])\n",
    "print('y_train:', y_train[:3])\n",
    "\n",
    "# print the shape of the training and testing data\n",
    "print('X_train shape:', (len(X_train), 1))\n",
    "print('y_train shape:', (len(y_train), 1))\n",
    "print('X_test shape:',(len( X_test), 1))\n",
    "print('y_test shape:',(len( y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training this model took 0.0047647953033447266 seconds.\n"
     ]
    }
   ],
   "source": [
    "# initialize classifier object\n",
    "movie_nb = nb.NaiveBayesClassifier()\n",
    "\n",
    "# train the model using the training data, timing how long the process takes\n",
    "start_time = time.time()\n",
    "movie_nb.train(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print('Training this model took', end_time-start_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "- **Accuracy**: Total correct predictions.\n",
    "- **Precision**: Percent of positive predictions that are truly positive.\n",
    "- **Recall**: Percentage of truly positive values that model predicts to be positive.\n",
    "- **F1 score**: A score that combines precision and recall\n",
    "\n",
    "Evaluate the Naive Bayes model for accuracy, precision, recall, and F1 scores with different combinatons of preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for plot in X_test:\n",
    "    genre_prediction = movie_nb.predict(plot)\n",
    "    y_pred.append(genre_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP WORDS REMOVED, LEMMATIZED\n",
      "Vocab size: 3544\n",
      "accuracy: 0.408\n",
      "precision: 0.38597460317460314\n",
      "recall: 0.408\n",
      "f1: 0.38307070707070706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahbernardo/opt/anaconda3/envs/ds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# STOP WORDS REMOVED, LEMMATIZED\n",
    "print('STOP WORDS REMOVED, LEMMATIZED')\n",
    "\n",
    "print('Vocab size:', movie_nb.get_vocab_size())\n",
    "\n",
    "# accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy:', accuracy)\n",
    "\n",
    "# precision score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print('precision:', precision)\n",
    "\n",
    "# recall score\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print('recall:', recall)\n",
    "\n",
    "# f1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print('f1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO STOP WORDS REMOVED, LEMMATIZED\n",
      "Training this model took 0.005822181701660156 seconds.\n",
      "Vocab size: 3646\n",
      "accuracy: 0.392\n",
      "precision: 0.47259376688884885\n",
      "recall: 0.392\n",
      "f1: 0.34647116324535676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahbernardo/opt/anaconda3/envs/ds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# NO STOP WORDS REMOVED, LEMMATIZED\n",
    "print('NO STOP WORDS REMOVED, LEMMATIZED')\n",
    "\n",
    "plots, genres = mdu.get_plots_genres('movie_plots.json',\\\n",
    "                                    stop_words = None)\n",
    "X_train, X_test, y_train, y_test = train_test_split(plots[:NUM_TRAINING_EXAMPLES], \n",
    "                                                    genres[:NUM_TRAINING_EXAMPLES], test_size=0.2, random_state=42)\n",
    "\n",
    "no_stop_nb = nb.NaiveBayesClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "no_stop_nb.train(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print('Training this model took', end_time-start_time, 'seconds.')\n",
    "\n",
    "print('Vocab size:', no_stop_nb.get_vocab_size())\n",
    "\n",
    "y_pred = []\n",
    "for plot in X_test:\n",
    "    genre_prediction = no_stop_nb.predict(plot)\n",
    "    y_pred.append(genre_prediction)\n",
    "\n",
    "# accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy:', accuracy)\n",
    "\n",
    "# precision score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print('precision:', precision)\n",
    "\n",
    "# recall score\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print('recall:', recall)\n",
    "\n",
    "# f1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print('f1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP WORDS REMOVED, NOT LEMMATIZED\n",
      "Training this model took 0.004684925079345703 seconds.\n",
      "Vocab size: 3858\n",
      "accuracy: 0.44\n",
      "precision: 0.4003618242222894\n",
      "recall: 0.44\n",
      "f1: 0.41282500797448163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahbernardo/opt/anaconda3/envs/ds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# STOP WORDS REMOVED, NOT LEMMATIZED\n",
    "print('STOP WORDS REMOVED, NOT LEMMATIZED')\n",
    "\n",
    "plots, genres = mdu.get_plots_genres('movie_plots.json',\\\n",
    "                                    lemmatizer=None)\n",
    "X_train, X_test, y_train, y_test = train_test_split(plots[:NUM_TRAINING_EXAMPLES], \n",
    "                                                    genres[:NUM_TRAINING_EXAMPLES], test_size=0.2, random_state=42)\n",
    "\n",
    "no_lem_nb = nb.NaiveBayesClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "no_lem_nb.train(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print('Training this model took', end_time-start_time, 'seconds.')\n",
    "\n",
    "print('Vocab size:', no_lem_nb.get_vocab_size())\n",
    "\n",
    "y_pred = []\n",
    "for plot in X_test:\n",
    "    genre_prediction = no_lem_nb.predict(plot)\n",
    "    y_pred.append(genre_prediction)\n",
    "\n",
    "\n",
    "# accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy:', accuracy)\n",
    "\n",
    "# precision score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print('precision:', precision)\n",
    "\n",
    "# recall score\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print('recall:', recall)\n",
    "\n",
    "# f1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print('f1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO STOP WORDS REMOVED, NOT LEMMATIZED\n",
      "Training this model took 0.0074617862701416016 seconds.\n",
      "Vocab size: 3965\n",
      "accuracy: 0.384\n",
      "precision: 0.412556586270872\n",
      "recall: 0.384\n",
      "f1: 0.3248672268907563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahbernardo/opt/anaconda3/envs/ds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# NO STOP WORDS REMOVED, NOT LEMMATIZED\n",
    "print('NO STOP WORDS REMOVED, NOT LEMMATIZED')\n",
    "\n",
    "plots, genres = mdu.get_plots_genres('movie_plots.json',\\\n",
    "                                    lemmatizer=None,\\\n",
    "                                    stop_words=None)\n",
    "X_train, X_test, y_train, y_test = train_test_split(plots[:NUM_TRAINING_EXAMPLES], \n",
    "                                                    genres[:NUM_TRAINING_EXAMPLES], test_size=0.2, random_state=42)\n",
    "\n",
    "none_nb = nb.NaiveBayesClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "none_nb.train(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print('Training this model took', end_time-start_time, 'seconds.')\n",
    "\n",
    "print('Vocab size:', none_nb.get_vocab_size())\n",
    "\n",
    "y_pred = []\n",
    "for plot in X_test:\n",
    "    genre_prediction = none_nb.predict(plot)\n",
    "    y_pred.append(genre_prediction)\n",
    "\n",
    "# accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy:', accuracy)\n",
    "\n",
    "# precision score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print('precision:', precision)\n",
    "\n",
    "# recall score\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print('recall:', recall)\n",
    "\n",
    "# f1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print('f1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These results show that this model is not very good at predicting the genres of these movies, but tweaking the preprocessing strategies can improve some metrics like accuracy and recall by up to 5%. This model trains much faster than predicted, but all of the accuracy, precision, recall, and f1-scores are below 45%. It seems to perform best in terms of accuracy and precision, and its f1 scores are the least optimized measurement. Because there are 15 different classes, it is much better than randomly guessing, which would give us a 6.67% accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary questions:\n",
    "-----\n",
    "\n",
    "| preprocessing strategies | accuracy | precision | recall | f1-score | vocabulary size | training time |\n",
    "| - | - | - | - | - | - | - |\n",
    "| No lemmatizing or stop word removal | 0.384 | 0.413 | 0.384 | 0.325 | 3,965 | 6.34e-3 |\n",
    "| Lemmatizing only | 0.392 | 0.473 | 0.392 | 0.346 | 3,646 | 5.97e-3 |\n",
    "| Stop word removal only | 0.44 | 0.4 | 0.44 | 0.413 | 3,858 | 4.81e-3 |\n",
    "| Both lemmatizing and stop word removal | 0.408 | 0.386 | 0.408 | 0.383 | 3,544 | 5.23e-3 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<p></p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
