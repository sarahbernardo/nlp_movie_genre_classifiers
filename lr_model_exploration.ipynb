{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sarah Bernardo\n",
    "\n",
    "CS 4120, Spring 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/sarahbernardo/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sarahbernardo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sarahbernardo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sarahbernardo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import lr_model as lr\n",
    "import movies_data_utils as mdu\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# load Wikipedia plot movie data from https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots\n",
    "NUM_TRAINING_EXAMPLES = 500\n",
    "NUM_ITERATIONS = 1000\n",
    "NUM_FEATURES = 5000\n",
    "LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "plots, genres = mdu.get_plots_genres('movie_plots.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn's TfidfVectorizer class to handle pre-processed data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=NUM_FEATURES)\n",
    "# this will return a sparse matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(plots)\n",
    "# change the sparse matrix to an array\n",
    "tfidf_matrix = tfidf_matrix.toarray()\n",
    "\n",
    "# split data into training/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix[:NUM_TRAINING_EXAMPLES], \n",
    "                                                    genres[:NUM_TRAINING_EXAMPLES], \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to help pre-processing\n",
    "def get_nonzero_pct(matrix: np.ndarray, row: int):\n",
    "    \"\"\" \n",
    "    Calculates percentage of non-zero elements in a row in a matrix.\n",
    "    Args:\n",
    "        matrix (np.ndarray): the matrix\n",
    "        row (int): row for which you want to calculate the percentage\n",
    "    \"\"\"\n",
    "    mshape = matrix.shape\n",
    "\n",
    "    non_zero_cnt = np.count_nonzero(matrix[row])\n",
    "    return non_zero_cnt / mshape[1] *100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "y_train: ['Children', 'Documentaries', 'Documentaries']\n",
      "Row 0 is 0.27999999999999997% non-zero elements\n",
      "Row 1 is 0.2% non-zero elements\n",
      "Row 2 is 0.22% non-zero elements\n"
     ]
    }
   ],
   "source": [
    "# see what the data looks like by printing first 10 elements, corresponding labels, and % of non-zero elements in first of 3 rows of the training set\n",
    "print('X_train:', X_train[:3])\n",
    "print('y_train:', y_train[:3])\n",
    "\n",
    "for i in range(3):\n",
    "    nonz_pct = get_nonzero_pct(X_train, i)\n",
    "    print(f'Row {i} is {nonz_pct}% non-zero elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This logistic regression model took 5.060145854949951 seconds to train on 500 training examples for 1000 iterations with 5000 features.\n"
     ]
    }
   ],
   "source": [
    "# initialize LR model.\n",
    "logreg = lr.LogisticRegression(LEARNING_RATE, NUM_ITERATIONS)\n",
    "\n",
    "# train model and measure how long the process took\n",
    "start_time = time.time()\n",
    "logreg.train(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'This logistic regression model took {(end_time-start_time)} seconds to train on {NUM_TRAINING_EXAMPLES} training examples for {NUM_ITERATIONS} iterations with {NUM_FEATURES} features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for example: Comedies\n"
     ]
    }
   ],
   "source": [
    "# predict the genre for one example from your test set.\n",
    "\n",
    "plot_example = X_test[0,:].reshape((-1,1))\n",
    "genre_example = np.array(y_test)[0]\n",
    "\n",
    "ex_pred = logreg.predict(plot_example)\n",
    "print('Prediction for example:', ex_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate Logistic Regression model with accuracy, precision, recall, and f1-score for predictions.\n",
    "y_pred = []\n",
    "for plot in X_test:\n",
    "    plot = plot.reshape((-1,1))\n",
    "    genre_prediction = logreg.predict(plot)\n",
    "    y_pred.append(genre_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.46\n",
      "precision: 0.4766031746031746\n",
      "recall: 0.46\n",
      "f1: 0.4429040598869821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahbernardo/opt/anaconda3/envs/ds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy:', accuracy)\n",
    "\n",
    "# precision score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print('precision:', precision)\n",
    "\n",
    "# recall score\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print('recall:', recall)\n",
    "\n",
    "# f1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print('f1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model is less than ideal, as none of these metrics exceed 48%, but it's not too much worse than my Naive Bayes model. It seems most optimal for precision, as the precision measure consistently returns the highest value. It seems that increasing the number of features is most impactful/most helpful, as that increased the measurements by the most. Overall, there is plenty of room for improvement, but this model is better than randomly guessing the genres.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "----\n",
    "Fill in the following table for Logistic Regression:\n",
    "\n",
    "| num training examples | num iterations | num features | accuracy | precision | recall | f1-score | training time |\n",
    "| - | - | - | - | - | - | - | - |\n",
    "| 500 | 1000 | 1000 | 0.37 | 0.417 | 0.37 | 0.369 | 1.81s |\n",
    "| 1000 | 1000 | 1000 | 0.435 | 0.402 | 0.435 | 0.415 | 2.42s |\n",
    "| 1500 | 1000 | 1000 | 0.45 | 0.437 | 0.45 | 0.438 | 3.85s |\n",
    "| 500 | 3000 | 1000 | 0.37 | 0.407 | 0.37 | 0.363 | 5.19s |\n",
    "| 500 | 5000 | 1000 | 0.37 | 0.401 | 0.37 | 0.363 | 6.05s |\n",
    "| 500 | 1000 | 3000 | 0.44 | 0.464 | 0.44 | 0.425 | 3.86s |\n",
    "| 500 | 1000 | 5000 | 0.46 | 0.477 | 0.46 | 0.443 | 5.91s |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahbernardo/Documents/4NU/cs4120/hw3/lr_model.py:95: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = np.sum(-(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))) / num_classes\n",
      "/Users/sarahbernardo/Documents/4NU/cs4120/hw3/lr_model.py:95: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = np.sum(-(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))) / num_classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.549\n",
      "precision: 0.532916106240845\n",
      "recall: 0.549\n",
      "f1: 0.5388365909599984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahbernardo/opt/anaconda3/envs/ds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAINING_EXAMPLES = 5000\n",
    "NUM_ITERATIONS = 5000\n",
    "NUM_FEATURES = 10000\n",
    "\n",
    "final_lr = lr.LogisticRegression(LEARNING_RATE, NUM_ITERATIONS)\n",
    "\n",
    "# PROVIDED\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=NUM_FEATURES)\n",
    "# this will return a sparse matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(plots)\n",
    "# change the sparse matrix to an array\n",
    "tfidf_matrix = tfidf_matrix.toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix[:NUM_TRAINING_EXAMPLES], \n",
    "                                                    genres[:NUM_TRAINING_EXAMPLES], \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "logreg.train(X_train, y_train)\n",
    "\n",
    "y_pred = []\n",
    "for plot in X_test:\n",
    "    plot = plot.reshape((-1,1))\n",
    "    genre_prediction = logreg.predict(plot)\n",
    "    y_pred.append(genre_prediction)\n",
    "\n",
    "# accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy:', accuracy)\n",
    "\n",
    "# precision score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print('precision:', precision)\n",
    "\n",
    "# recall score\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print('recall:', recall)\n",
    "\n",
    "# f1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print('f1:', f1)\n",
    "\n",
    "mdu.save_predictions(y_test, y_pred, \"lr_predictions.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
